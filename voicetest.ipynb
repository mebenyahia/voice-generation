{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAd5noY8AeZB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a80ae81f-9e0c-45b8-d55d-b902136f0ec3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting TTS\n",
            "  Downloading TTS-0.11.1-cp38-cp38-manylinux1_x86_64.whl (604 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m604.1/604.1 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from TTS) (6.0)\n",
            "Collecting coqpit>=0.0.16\n",
            "  Downloading coqpit-0.0.17-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: fsspec>=2021.04.0 in /usr/local/lib/python3.8/dist-packages (from TTS) (2023.1.0)\n",
            "Collecting unidic-lite==1.0.8\n",
            "  Downloading unidic-lite-1.0.8.tar.gz (47.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pysbd\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 KB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gruut[de]==2.2.3\n",
            "  Downloading gruut-2.2.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 KB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting g2pkk>=0.1.1\n",
            "  Downloading g2pkk-0.1.2-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from TTS) (1.7.3)\n",
            "Collecting librosa==0.8.0\n",
            "  Downloading librosa-0.8.0.tar.gz (183 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 KB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.8/dist-packages (from TTS) (0.11.0)\n",
            "Collecting mecab-python3==1.0.5\n",
            "  Downloading mecab_python3-1.0.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (577 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m577.3/577.3 KB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from TTS) (3.2.2)\n",
            "Collecting cython==0.29.28\n",
            "  Downloading Cython-0.29.28-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from TTS) (1.3.5)\n",
            "Requirement already satisfied: numpy==1.21.6 in /usr/local/lib/python3.8/dist-packages (from TTS) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from TTS) (23.0)\n",
            "Collecting numba==0.55.1\n",
            "  Downloading numba-0.55.1-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio in /usr/local/lib/python3.8/dist-packages (from TTS) (0.13.1+cu116)\n",
            "Collecting pypinyin\n",
            "  Downloading pypinyin-0.48.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trainer==0.0.20\n",
            "  Downloading trainer-0.0.20-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 KB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting inflect==5.6.0\n",
            "  Downloading inflect-5.6.0-py3-none-any.whl (33 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.5/287.5 KB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from TTS) (4.64.1)\n",
            "Collecting jamo\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.8/dist-packages (from TTS) (1.1.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from TTS) (3.7)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.8/dist-packages (from TTS) (0.42.1)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.8/dist-packages (from TTS) (1.13.1+cu116)\n",
            "Collecting umap-learn==0.5.1\n",
            "  Downloading umap-learn-0.5.1.tar.gz (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 KB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.8/dist-packages (from gruut[de]==2.2.3->TTS) (2.11.0)\n",
            "Collecting dateparser~=1.1.0\n",
            "  Downloading dateparser-1.1.7-py2.py3-none-any.whl (293 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.4/293.4 KB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gruut-ipa<1.0,>=0.12.0\n",
            "  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 KB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_en~=2.0.0\n",
            "  Downloading gruut_lang_en-2.0.0.tar.gz (15.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonlines~=1.2.0\n",
            "  Downloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting networkx<3.0.0,>=2.5.0\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting num2words<1.0.0,>=0.5.10\n",
            "  Downloading num2words-0.5.12-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 KB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-crfsuite~=0.9.7\n",
            "  Downloading python_crfsuite-0.9.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib_resources in /usr/local/lib/python3.8/dist-packages (from gruut[de]==2.2.3->TTS) (5.10.2)\n",
            "Collecting gruut_lang_de~=2.0.0\n",
            "  Downloading gruut_lang_de-2.0.0.tar.gz (18.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.0->TTS) (3.0.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.0->TTS) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.0->TTS) (1.2.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.0->TTS) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.0->TTS) (0.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.0->TTS) (1.6.0)\n",
            "Collecting llvmlite<0.39,>=0.38.0rc1\n",
            "  Downloading llvmlite-0.38.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba==0.55.1->TTS) (57.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from trainer==0.0.20->TTS) (3.19.6)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 KB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from trainer==0.0.20->TTS) (5.4.8)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.8.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile->TTS) (1.15.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7->TTS) (4.4.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.8/dist-packages (from flask->TTS) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.8/dist-packages (from flask->TTS) (1.1.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.8/dist-packages (from flask->TTS) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.8/dist-packages (from flask->TTS) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->TTS) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->TTS) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->TTS) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->TTS) (1.4.4)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk->TTS) (2022.6.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->TTS) (2022.7.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile->TTS) (2.21)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.8/dist-packages (from dateparser~=1.1.0->gruut[de]==2.2.3->TTS) (1.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2<3.0,>=2.10.1->flask->TTS) (2.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from jsonlines~=1.2.0->gruut[de]==2.2.3->TTS) (1.15.0)\n",
            "Collecting docopt>=0.6.2\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa==0.8.0->TTS) (2.25.1)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa==0.8.0->TTS) (1.4.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.0->TTS) (3.1.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib_resources->gruut[de]==2.2.3->TTS) (3.12.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->TTS) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->TTS) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->TTS) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->TTS) (4.0.0)\n",
            "Building wheels for collected packages: librosa, umap-learn, unidic-lite, gruut-ipa, gruut_lang_de, gruut_lang_en, pynndescent, gruut, docopt\n",
            "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for librosa: filename=librosa-0.8.0-py3-none-any.whl size=201396 sha256=d47e68b1f0e893266d51c75911172e919fc5170b1e651aff20c082a0703ea14c\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/5a/92/d52f6f8560ff05a2525e6030a1903412df876714241fb76802\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.1-py3-none-any.whl size=76566 sha256=08cce56601d7dea0204cc6b0d8681ce44085977ffe45aa746a17b639f4e2549f\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/85/b7/b4b7040e49367b6d1505d7e8fb57e3e79b22fa6ac26f72520b\n",
            "  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unidic-lite: filename=unidic_lite-1.0.8-py3-none-any.whl size=47658837 sha256=eb7225205fa01c72ef32c435411ce11038ac3dbc85ba0a5c51208d11aef121fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/dd/8f/e21fc192dcd38ae31e1185ce4e66e12df4e811e3d469866e15\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-ipa: filename=gruut_ipa-0.13.0-py3-none-any.whl size=104895 sha256=7849e5d8561b0e4bace95249f46a0dd92c5c32a1f500848d7a546f2b1c04f7a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/ef/27/f88344c08d8cca457a5316a39b099505e68a9f2a0547e0c5e7\n",
            "  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_de: filename=gruut_lang_de-2.0.0-py3-none-any.whl size=18498199 sha256=d70584f57390c81c68ea76b2f5035c8ef38c9c90705b1bfde30e175d761dfc2e\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/e1/60/d80ef587c3dd944644291065719d35ff92747b8e65135b2aa5\n",
            "  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_en: filename=gruut_lang_en-2.0.0-py3-none-any.whl size=15297198 sha256=aedd76b83a95454176ef8eb6251ec076508533d94c2f79e06187207de1c30df4\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f7/60/ddc598856abe98015bfefa228160da28a0d5d0ba39b4c7ddf4\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.8-py3-none-any.whl size=55513 sha256=07ff47039381b68ebd9755a2795cfd73c5454d1840c48d6707347be6b36cdfd3\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/63/3a/29954bca1a27ba100ed8c27973a78cb71b43dc67aed62e80c3\n",
            "  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut: filename=gruut-2.2.3-py3-none-any.whl size=75819 sha256=983fb34513f90fe5373e49e416a98996f97795864756cdd8e1facda0a8909ec4\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/77/15/4d57c0e698b2340faa0ca0b1638ffce2683aacc4e41d5123d8\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=ce6a8038cb28f6954bcf85145be42695b3485df1e4dc001818ae31a534557ab9\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
            "Successfully built librosa umap-learn unidic-lite gruut-ipa gruut_lang_de gruut_lang_en pynndescent gruut docopt\n",
            "Installing collected packages: unidic-lite, python-crfsuite, mecab-python3, jamo, gruut_lang_en, gruut_lang_de, docopt, tensorboardX, pysbd, pypinyin, num2words, networkx, llvmlite, jsonlines, inflect, gruut-ipa, cython, coqpit, anyascii, numba, g2pkk, dateparser, trainer, pynndescent, gruut, umap-learn, librosa, TTS\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.0\n",
            "    Uninstalling networkx-3.0:\n",
            "      Successfully uninstalled networkx-3.0\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.39.1\n",
            "    Uninstalling llvmlite-0.39.1:\n",
            "      Successfully uninstalled llvmlite-0.39.1\n",
            "  Attempting uninstall: inflect\n",
            "    Found existing installation: inflect 2.1.0\n",
            "    Uninstalling inflect-2.1.0:\n",
            "      Successfully uninstalled inflect-2.1.0\n",
            "  Attempting uninstall: cython\n",
            "    Found existing installation: Cython 0.29.33\n",
            "    Uninstalling Cython-0.29.33:\n",
            "      Successfully uninstalled Cython-0.29.33\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.56.4\n",
            "    Uninstalling numba-0.56.4:\n",
            "      Successfully uninstalled numba-0.56.4\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.8.1\n",
            "    Uninstalling librosa-0.8.1:\n",
            "      Successfully uninstalled librosa-0.8.1\n",
            "Successfully installed TTS-0.11.1 anyascii-0.3.1 coqpit-0.0.17 cython-0.29.28 dateparser-1.1.7 docopt-0.6.2 g2pkk-0.1.2 gruut-2.2.3 gruut-ipa-0.13.0 gruut_lang_de-2.0.0 gruut_lang_en-2.0.0 inflect-5.6.0 jamo-0.4.1 jsonlines-1.2.0 librosa-0.8.0 llvmlite-0.38.1 mecab-python3-1.0.5 networkx-2.8.8 num2words-0.5.12 numba-0.55.1 pynndescent-0.5.8 pypinyin-0.48.0 pysbd-0.3.4 python-crfsuite-0.9.9 tensorboardX-2.5.1 trainer-0.0.20 umap-learn-0.5.1 unidic-lite-1.0.8\n"
          ]
        }
      ],
      "source": [
        "pip install TTS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from TTS.utils.synthesizer import Synthesizer"
      ],
      "metadata": {
        "id": "-ICMD40xBLyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from TTS.utils.manage import ModelManager"
      ],
      "metadata": {
        "id": "z2XH_qOVCONq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show TTS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw-cB-mwDHDU",
        "outputId": "7ec62a00-3be7-4096-f279-aed7fb617c14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: TTS\n",
            "Version: 0.11.1\n",
            "Summary: Deep learning for Text to Speech by Coqui.\n",
            "Home-page: https://github.com/coqui-ai/TTS\n",
            "Author: Eren Gölge\n",
            "Author-email: egolge@coqui.ai\n",
            "License: MPL-2.0\n",
            "Location: /usr/local/lib/python3.8/dist-packages\n",
            "Requires: anyascii, coqpit, cython, flask, fsspec, g2pkk, gruut, inflect, jamo, jieba, librosa, matplotlib, mecab-python3, nltk, numba, numpy, packaging, pandas, pypinyin, pysbd, pyyaml, scipy, soundfile, torch, torchaudio, tqdm, trainer, umap-learn, unidic-lite\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/usr/local/lib/python3.8/dist-packages/TTS/.models.json'"
      ],
      "metadata": {
        "id": "n9oGcHT5DU6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_manager = ModelManager(path)"
      ],
      "metadata": {
        "id": "rCv5Fa4VDmgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path, config_path, model_item = model_manager.download_model(\"tts_models/en/ljspeech/tacotron2-DDC\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXzzy180D3xA",
        "outputId": "fc3eb998-b116-4353-a6c0-e940db2cce64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Downloading model to /root/.local/share/tts/tts_models--en--ljspeech--tacotron2-DDC\n",
            " > Model's license - apache 2.0\n",
            " > Check https://choosealicense.com/licenses/apache-2.0/ for more info.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "voc_path, voc_config_path, _ = model_manager.download_model(model_item[\"default_vocoder\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLOGDlewEEVI",
        "outputId": "f204de93-1562-412f-9167-ef4b0743abbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Downloading model to /root/.local/share/tts/vocoder_models--en--ljspeech--hifigan_v2\n",
            " > Model's license - apache 2.0\n",
            " > Check https://choosealicense.com/licenses/apache-2.0/ for more info.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "syn = Synthesizer(\n",
        "    tts_checkpoint=model_path,\n",
        "    tts_config_path=config_path,\n",
        "    vocoder_checkpoint=voc_path,\n",
        "    vocoder_config=voc_config_path\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-SjFHwtEMT9",
        "outputId": "e8260b15-9374-4923-d630-b9cf61b7dd8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Using model: Tacotron2\n",
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log\n",
            " | > min_level_db:-100\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:20\n",
            " | > fft_size:1024\n",
            " | > power:1.5\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:60\n",
            " | > signal_norm:False\n",
            " | > symmetric_norm:True\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:8000.0\n",
            " | > pitch_fmin:1.0\n",
            " | > pitch_fmax:640.0\n",
            " | > spec_gain:1.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:4.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:True\n",
            " | > trim_db:60\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:2.718281828459045\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n",
            " > Model's reduction rate `r` is set to: 1\n",
            " > Vocoder Model: hifigan\n",
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log\n",
            " | > min_level_db:-100\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:20\n",
            " | > fft_size:1024\n",
            " | > power:1.5\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:60\n",
            " | > signal_norm:False\n",
            " | > symmetric_norm:True\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:8000.0\n",
            " | > pitch_fmin:1.0\n",
            " | > pitch_fmax:640.0\n",
            " | > spec_gain:1.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:4.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:False\n",
            " | > trim_db:60\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:2.718281828459045\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n",
            " > Generator Model: hifigan_generator\n",
            " > Discriminator Model: hifigan_discriminator\n",
            "Removing weight norm...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I'm tired of this shit\"\n",
        "outputs = syn.tts(text)\n",
        "syn.save_wav(outputs, \"audio-1.wav\")"
      ],
      "metadata": {
        "id": "fzXVK7FpEmRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe521672-b6d8-436a-86b0-9a03a6efbf7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Text splitted to sentences.\n",
            "[\"I'm tired of this shit\"]\n",
            " > Processing time: 1.1871628761291504\n",
            " > Real-time factor: 0.5136762444789593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(filename):\n",
        "\twith open(filename, \"r\") as file:\n",
        "\t\tlines = file.readlines()\n",
        "\treturn lines"
      ],
      "metadata": {
        "id": "-syR8WxIRmbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_file_lines = read_file(\"sentences.txt\")\n",
        "messages = [line.strip() for line in text_file_lines]\n",
        "\n",
        "print(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJU1MAv7Rw3N",
        "outputId": "630e3665-ee6e-4c35-9079-5af8fe7f3678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"You're amazing!\", 'Keep shining!', 'You inspire others!', \"You're strong!\", 'Your potential is unlimited!', 'Your courage is admirable!', 'Your kindness touches hearts!', 'Your smile brightens days!', 'You bring joy to others!', \"You're valued and appreciated!\", 'Your determination is inspiring!', \"You're unique and special!\", 'Your perseverance pays off!', 'Your passion lights the way!', 'You make a positive impact!', 'You have a wonderful spirit!', \"You're a blessing to others!\", \"You're making a difference!\", \"You're more than enough!\", 'Your journey is remarkable!', \"I love you just the way You're!\", 'You bring joy to my life!', 'I am grateful for you!', 'You make everything better!', 'I cherish our moments together!', \"You're my sunshine!\", 'I appreciate all you do!', 'You make my heart full!', \"I'm lucky to have you!\", 'I love spending time with you!', \"You're loved!\", 'You make a difference!', \"You're strong!\", 'Everything will work out!', \"You're amazing!\", 'I believe in you!', 'Your smile lights up the room!', \"You're not alone!\", \"You're capable!\", 'I love you more every day!', 'You mean everything to me!', 'My heart is filled with love for you!', 'I am so lucky to have you!', 'You bring happiness to my life!', 'I cherish every moment with you!', \"You're my everything!\", 'I love you more than words can say!', \"I can't imagine life without you!\", 'I am grateful for you, every day!', \"You're stunning!\", 'Your beauty shines bright!', \"You're gorgeous inside and out!\", \"You're a work of art!\", 'Your smile lights up the room!', \"You're simply radiant!\", \"You're a breath of fresh air!\", 'Your inner beauty shines through!', \"You're a beautiful person!\", 'Your beauty is contagious!', 'You matter to me!', 'You make a difference!', 'Your presence matters!', \"You're valuable!\", 'Your thoughts and feelings matter!', \"You're important!\", 'Your contributions matter!', 'Your existence matters!', 'You matter to the world!', 'Your impact is significant!', 'I love you!', 'Are you French? Because Eiffel for you.', 'Aside from being perfect, what do you do for a living?', 'If you were a chicken, you’d be impeccable.', 'If you were words on a page, you’d be fine print.', 'I was wondering if you had an extra heart. Because mine was just stolen.', 'Somebody better call God, because he’s missing an angel!', \"You're so beautiful that you made me forget my line.\\u200b\", 'Did the sun come out, or did you just smile?', \"You've swept me off my feet.\", \"If you were a fruit, you'd be a fine-apple.\", \"If you were a vegetable, you'd be a cute-cumber.\", 'What is it like to be the most gorgeous person in this room?', 'When God made you, he was really just showing off.', 'What is it like to be the most gorgeous person in this room?', \"I'm not an organ donor, but I'm ready to give you my heart.\", 'Anyone who says Disneyland is the happiest place on earth has clearly never stood next to you.', \"I'd say God bless you, but it looks like he already has.\", \"I'd never play hide and seek with you, because someone like you is impossible to find.\", 'I think someone must have stolen the stars and put them in your eyes.', 'The sparkle in your eye is so bright, the sun and stars must be jealous.', 'When God made you, he was really just showing off.', \"You're so beautiful!\", \"I'm not sure what it is about you, but you're just so perfect!\", \"You're so good-looking I'm literally speechless.\", 'Stunning.', 'Did it hurt? When you fell from heaven.', \"You need to know this: you're loved more than you could ever know. I love you.\", \"You're so sweet you must be made out of chocolate.\", \"I don't know how this works. Are we married now?\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_speech(text_list):\n",
        "  for t in text_list:\n",
        "    filename = t.strip('!') + \".mp3\"\n",
        "    output = syn.tts(t)\n",
        "    syn.save_wav(output, filename)"
      ],
      "metadata": {
        "id": "VRda-WfoR0oR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_speech(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fqjNju3fSLbj",
        "outputId": "5f9517fe-d707-40a8-b0e3-ca2e4ca5dd36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Text splitted to sentences.\n",
            "[\"You're amazing!\"]\n",
            " > Processing time: 0.9654290676116943\n",
            " > Real-time factor: 0.5616217533990571\n",
            " > Text splitted to sentences.\n",
            "['Keep shining!']\n",
            " > Processing time: 0.7599718570709229\n",
            " > Real-time factor: 0.49566314033405845\n",
            " > Text splitted to sentences.\n",
            "['You inspire others!']\n",
            " > Processing time: 1.23628568649292\n",
            " > Real-time factor: 0.5723064197843653\n",
            " > Text splitted to sentences.\n",
            "[\"You're strong!\"]\n",
            " > Processing time: 0.9267604351043701\n",
            " > Real-time factor: 0.5215156082597836\n",
            " > Text splitted to sentences.\n",
            "['Your potential is unlimited!']\n",
            " > Processing time: 1.4239604473114014\n",
            " > Real-time factor: 0.589484977906586\n",
            " > Text splitted to sentences.\n",
            "['Your courage is admirable!']\n",
            " > Processing time: 1.3718080520629883\n",
            " > Real-time factor: 0.5762032830689746\n",
            " > Text splitted to sentences.\n",
            "['Your kindness touches hearts!']\n",
            " > Processing time: 1.6446175575256348\n",
            " > Real-time factor: 0.6130615557113919\n",
            " > Text splitted to sentences.\n",
            "['Your smile brightens days!']\n",
            " > Processing time: 1.618453025817871\n",
            " > Real-time factor: 0.6059306102160428\n",
            " > Text splitted to sentences.\n",
            "['You bring joy to others!']\n",
            " > Processing time: 1.3155179023742676\n",
            " > Real-time factor: 0.5692144769888658\n",
            " > Text splitted to sentences.\n",
            "[\"You're valued and appreciated!\"]\n",
            " > Processing time: 1.7382893562316895\n",
            " > Real-time factor: 0.6262954298187705\n",
            " > Text splitted to sentences.\n",
            "['Your determination is inspiring!']\n",
            " > Processing time: 1.6100976467132568\n",
            " > Real-time factor: 0.608088741950317\n",
            " > Text splitted to sentences.\n",
            "[\"You're unique and special!\"]\n",
            " > Processing time: 1.811784267425537\n",
            " > Real-time factor: 0.6118268055735895\n",
            " > Text splitted to sentences.\n",
            "['Your perseverance pays off!']\n",
            " > Processing time: 1.449145793914795\n",
            " > Real-time factor: 0.5885953572764004\n",
            " > Text splitted to sentences.\n",
            "['Your passion lights the way!']\n",
            " > Processing time: 1.448812484741211\n",
            " > Real-time factor: 0.5940626913222199\n",
            " > Text splitted to sentences.\n",
            "['You make a positive impact!']\n",
            " > Processing time: 1.4579856395721436\n",
            " > Real-time factor: 0.589406412301367\n",
            " > Text splitted to sentences.\n",
            "['You have a wonderful spirit!']\n",
            " > Processing time: 1.4315505027770996\n",
            " > Real-time factor: 0.5842035939116643\n",
            " > Text splitted to sentences.\n",
            "[\"You're a blessing to others!\"]\n",
            " > Processing time: 1.420295238494873\n",
            " > Real-time factor: 0.5851552692229438\n",
            " > Text splitted to sentences.\n",
            "[\"You're making a difference!\"]\n",
            " > Processing time: 1.5842821598052979\n",
            " > Real-time factor: 0.6063145935800266\n",
            " > Text splitted to sentences.\n",
            "[\"You're more than enough!\"]\n",
            " > Processing time: 1.1394789218902588\n",
            " > Real-time factor: 0.554304408482179\n",
            " > Text splitted to sentences.\n",
            "['Your journey is remarkable!']\n",
            " > Processing time: 1.2377057075500488\n",
            " > Real-time factor: 0.5638721250305491\n",
            " > Text splitted to sentences.\n",
            "[\"I love you just the way You're!\"]\n",
            " > Processing time: 1.549630880355835\n",
            " > Real-time factor: 0.6120908733133806\n",
            " > Text splitted to sentences.\n",
            "['You bring joy to my life!']\n",
            " > Processing time: 1.3902080059051514\n",
            " > Real-time factor: 0.5810980916402901\n",
            " > Text splitted to sentences.\n",
            "['I am grateful for you!']\n",
            " > Processing time: 1.2229135036468506\n",
            " > Real-time factor: 0.5661161142805899\n",
            " > Text splitted to sentences.\n",
            "['You make everything better!']\n",
            " > Processing time: 1.1668164730072021\n",
            " > Real-time factor: 0.5644152165191472\n",
            " > Text splitted to sentences.\n",
            "['I cherish our moments together!']\n",
            " > Processing time: 1.4064455032348633\n",
            " > Real-time factor: 0.5850460939165548\n",
            " > Text splitted to sentences.\n",
            "[\"You're my sunshine!\"]\n",
            " > Processing time: 1.318904161453247\n",
            " > Real-time factor: 0.5853831876015317\n",
            " > Text splitted to sentences.\n",
            "['I appreciate all you do!']\n",
            " > Processing time: 1.3999533653259277\n",
            " > Real-time factor: 0.574028780597975\n",
            " > Text splitted to sentences.\n",
            "['You make my heart full!']\n",
            " > Processing time: 1.1505849361419678\n",
            " > Real-time factor: 0.5693536320002331\n",
            " > Text splitted to sentences.\n",
            "[\"I'm lucky to have you!\"]\n",
            " > Processing time: 1.1196658611297607\n",
            " > Real-time factor: 0.5477598561836888\n",
            " > Text splitted to sentences.\n",
            "['I love spending time with you!']\n",
            " > Processing time: 1.527214527130127\n",
            " > Real-time factor: 0.5950501894829534\n",
            " > Text splitted to sentences.\n",
            "[\"You're loved!\"]\n",
            " > Processing time: 0.8139278888702393\n",
            " > Real-time factor: 0.5005329637881742\n",
            " > Text splitted to sentences.\n",
            "['You make a difference!']\n",
            " > Processing time: 1.0201599597930908\n",
            " > Real-time factor: 0.5421935767797351\n",
            " > Text splitted to sentences.\n",
            "[\"You're strong!\"]\n",
            " > Processing time: 0.9368722438812256\n",
            " > Real-time factor: 0.5306728570073218\n",
            " > Text splitted to sentences.\n",
            "['Everything will work out!']\n",
            " > Processing time: 1.1887593269348145\n",
            " > Real-time factor: 0.5532789420574269\n",
            " > Text splitted to sentences.\n",
            "[\"You're amazing!\"]\n",
            " > Processing time: 0.8926939964294434\n",
            " > Real-time factor: 0.5089962407237595\n",
            " > Text splitted to sentences.\n",
            "['I believe in you!']\n",
            " > Processing time: 0.8963139057159424\n",
            " > Real-time factor: 0.5076993840175845\n",
            " > Text splitted to sentences.\n",
            "['Your smile lights up the room!']\n",
            " > Processing time: 1.503960371017456\n",
            " > Real-time factor: 0.596788190702111\n",
            " > Text splitted to sentences.\n",
            "[\"You're not alone!\"]\n",
            " > Processing time: 1.0359625816345215\n",
            " > Real-time factor: 0.5405853588849204\n",
            " > Text splitted to sentences.\n",
            "[\"You're capable!\"]\n",
            " > Processing time: 0.835228681564331\n",
            " > Real-time factor: 0.5136320958415188\n",
            " > Text splitted to sentences.\n",
            "['I love you more every day!']\n",
            " > Processing time: 1.312739372253418\n",
            " > Real-time factor: 0.5796600279995968\n",
            " > Text splitted to sentences.\n",
            "['You mean everything to me!']\n",
            " > Processing time: 1.2353847026824951\n",
            " > Real-time factor: 0.5718893326786408\n",
            " > Text splitted to sentences.\n",
            "['My heart is filled with love for you!']\n",
            " > Processing time: 1.8661003112792969\n",
            " > Real-time factor: 0.6086910039010133\n",
            " > Text splitted to sentences.\n",
            "['I am so lucky to have you!']\n",
            " > Processing time: 1.4520435333251953\n",
            " > Real-time factor: 0.5815453340202804\n",
            " > Text splitted to sentences.\n",
            "['You bring happiness to my life!']\n",
            " > Processing time: 1.594259262084961\n",
            " > Real-time factor: 0.5917286683438828\n",
            " > Text splitted to sentences.\n",
            "['I cherish every moment with you!']\n",
            " > Processing time: 1.56467866897583\n",
            " > Real-time factor: 0.5961633372082709\n",
            " > Text splitted to sentences.\n",
            "[\"You're my everything!\"]\n",
            " > Processing time: 1.0968737602233887\n",
            " > Real-time factor: 0.5490843264830576\n",
            " > Text splitted to sentences.\n",
            "['I love you more than words can say!']\n",
            " > Processing time: 1.9039406776428223\n",
            " > Real-time factor: 0.6257734906693333\n",
            " > Text splitted to sentences.\n",
            "[\"I can't imagine life without you!\"]\n",
            " > Processing time: 1.7930843830108643\n",
            " > Real-time factor: 0.6200989749904259\n",
            " > Text splitted to sentences.\n",
            "['I am grateful for you, every day!']\n",
            " > Processing time: 2.28242826461792\n",
            " > Real-time factor: 0.62596446809484\n",
            " > Text splitted to sentences.\n",
            "[\"You're stunning!\"]\n",
            " > Processing time: 0.8593008518218994\n",
            " > Real-time factor: 0.5032826121619444\n",
            " > Text splitted to sentences.\n",
            "['Your beauty shines bright!']\n",
            " > Processing time: 1.510786771774292\n",
            " > Real-time factor: 0.5967477844228851\n",
            " > Text splitted to sentences.\n",
            "[\"You're gorgeous inside and out!\"]\n",
            " > Processing time: 1.6236035823822021\n",
            " > Real-time factor: 0.6026201688581935\n",
            " > Text splitted to sentences.\n",
            "[\"You're a work of art!\"]\n",
            " > Processing time: 1.2484991550445557\n",
            " > Real-time factor: 0.571813857775267\n",
            " > Text splitted to sentences.\n",
            "['Your smile lights up the room!']\n",
            " > Processing time: 1.5587046146392822\n",
            " > Real-time factor: 0.6045848007457812\n",
            " > Text splitted to sentences.\n",
            "[\"You're simply radiant!\"]\n",
            " > Processing time: 1.2759525775909424\n",
            " > Real-time factor: 0.5692528798939842\n",
            " > Text splitted to sentences.\n",
            "[\"You're a breath of fresh air!\"]\n",
            " > Processing time: 1.6666498184204102\n",
            " > Real-time factor: 0.6030065059098524\n",
            " > Text splitted to sentences.\n",
            "['Your inner beauty shines through!']\n",
            " > Processing time: 1.649156093597412\n",
            " > Real-time factor: 0.601732391180549\n",
            " > Text splitted to sentences.\n",
            "[\"You're a beautiful person!\"]\n",
            " > Processing time: 1.4744617938995361\n",
            " > Real-time factor: 0.5719089951358847\n",
            " > Text splitted to sentences.\n",
            "['Your beauty is contagious!']\n",
            " > Processing time: 1.5526208877563477\n",
            " > Real-time factor: 0.586381381457719\n",
            " > Text splitted to sentences.\n",
            "['You matter to me!']\n",
            " > Processing time: 0.8057858943939209\n",
            " > Real-time factor: 0.5138702849197696\n",
            " > Text splitted to sentences.\n",
            "['You make a difference!']\n",
            " > Processing time: 1.0242948532104492\n",
            " > Real-time factor: 0.5546586815641062\n",
            " > Text splitted to sentences.\n",
            "['Your presence matters!']\n",
            " > Processing time: 1.167288064956665\n",
            " > Real-time factor: 0.5492211896614558\n",
            " > Text splitted to sentences.\n",
            "[\"You're valuable!\"]\n",
            " > Processing time: 0.9404711723327637\n",
            " > Real-time factor: 0.5190576028718822\n",
            " > Text splitted to sentences.\n",
            "['Your thoughts and feelings matter!']\n",
            " > Processing time: 1.5209369659423828\n",
            " > Real-time factor: 0.5952971474550828\n",
            " > Text splitted to sentences.\n",
            "[\"You're important!\"]\n",
            " > Processing time: 0.8994536399841309\n",
            " > Real-time factor: 0.5128504541179687\n",
            " > Text splitted to sentences.\n",
            "['Your contributions matter!']\n",
            " > Processing time: 1.2775657176971436\n",
            " > Real-time factor: 0.5699725654585225\n",
            " > Text splitted to sentences.\n",
            "['Your existence matters!']\n",
            " > Processing time: 1.2993724346160889\n",
            " > Real-time factor: 0.5888515739741196\n",
            " > Text splitted to sentences.\n",
            "['You matter to the world!']\n",
            " > Processing time: 1.134702444076538\n",
            " > Real-time factor: 0.5427843824168618\n",
            " > Text splitted to sentences.\n",
            "['Your impact is significant!']\n",
            " > Processing time: 1.4884343147277832\n",
            " > Real-time factor: 0.59062727900496\n",
            " > Text splitted to sentences.\n",
            "['I love you!']\n",
            " > Processing time: 0.7865116596221924\n",
            " > Real-time factor: 0.49067966542183516\n",
            " > Text splitted to sentences.\n",
            "['Are you French?', 'Because Eiffel for you.']\n",
            " > Processing time: 4.939112901687622\n",
            " > Real-time factor: 0.6367366667575541\n",
            " > Text splitted to sentences.\n",
            "['Aside from being perfect, what do you do for a living?']\n",
            " > Processing time: 14.547150611877441\n",
            " > Real-time factor: 0.7139272795482212\n",
            " > Text splitted to sentences.\n",
            "['If you were a chicken, you’d be impeccable.']\n",
            " > Processing time: 2.1364052295684814\n",
            " > Real-time factor: 0.6236461463670967\n",
            " > Text splitted to sentences.\n",
            "['If you were words on a page, you’d be fine print.']\n",
            " > Processing time: 2.786592721939087\n",
            " > Real-time factor: 0.6450987896728211\n",
            " > Text splitted to sentences.\n",
            "['I was wondering if you had an extra heart.', 'Because mine was just stolen.']\n",
            " > Processing time: 3.5701189041137695\n",
            " > Real-time factor: 0.6111888341281725\n",
            " > Text splitted to sentences.\n",
            "['Somebody better call God, because he’s missing an angel!']\n",
            " > Processing time: 2.726619243621826\n",
            " > Real-time factor: 0.6433182922643946\n",
            " > Text splitted to sentences.\n",
            "[\"You're so beautiful that you made me forget my line.\", '\\u200b']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-1459f8d7f9a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext_to_speech\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-58-4372b4d5f453>\u001b[0m in \u001b[0;36mtext_to_speech\u001b[0;34m(text_list)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'!'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".mp3\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msyn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0msyn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/TTS/utils/synthesizer.py\u001b[0m in \u001b[0;36mtts\u001b[0;34m(self, text, speaker_name, language_name, speaker_wav, style_wav, style_text, reference_wav, reference_speaker_name)\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msen\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                 \u001b[0;31m# synthesize voice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m                 outputs = synthesis(\n\u001b[0m\u001b[1;32m    279\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtts_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m                     \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/TTS/tts/utils/synthesis.py\u001b[0m in \u001b[0;36msynthesis\u001b[0;34m(model, text, CONFIG, use_cuda, speaker_id, style_wav, style_text, use_griffin_lim, do_trim_silence, d_vector, language_id)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0mtext_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;31m# synthesize voice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     outputs = run_model_torch(\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mtext_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/TTS/tts/utils/synthesis.py\u001b[0m in \u001b[0;36mrun_model_torch\u001b[0;34m(model, inputs, speaker_id, style_mel, style_text, d_vector, language_id)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0m_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     outputs = _func(\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         aux_input={\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/TTS/tts/models/tacotron2.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, text, aux_input)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0maux_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_aux_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0membedded_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgst\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_gst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/TTS/tts/layers/tacotron/tacotron2.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolutions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# self.lstm.flatten_parameters()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/TTS/tts/layers/tacotron/tacotron2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolution1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    307\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m--> 309\u001b[0;31m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    310\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (4). Kernel size: (5). Kernel size can't be greater than actual input size"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3vFPpL0QTURa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}